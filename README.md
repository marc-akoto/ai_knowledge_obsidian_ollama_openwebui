# Local AI-powered Knowledge Base

Turning AI and your technical Know-How into a private knowledge base, owned ğŸ’¯ by your team.

Your private, lightweight, local AI ğŸ›¡ï¸ with just 50 lines of docker-compose code in Portainer.

- **INPUT** : knowledge and technical notes in an Obsidian vault
- stored at the edge, synced across local servers by Syncthing
- enriched tech notes retrieval, with Arctic-Embed RAG by Snowflake
- fed into the lightweight 7B language model Q2_K by Mistral-ai
- **OUTPUT** : interactive knowledge chatbot with Open-WebUI


# The Stack #opensource

![Image overview](./images/RAG_LLM_AI_Obsidian_Ollama_OpenWebUI.jpg)


# Advantages

- âœ… **BUSINESS competitiveness**

Nowadays you can compete with the top engineering spheres ğŸš€ by just leveraging an opensource AI model and a lightweight GPU. Being a small team has never been so competitive. By analyzing our past track record, AI can bring expert suggestions, like a 2nd brain alive, or a specialized assistant. For such a specific knowledge domains as IndustrialAutomation ğŸ‘·, our competitiveness increases by mixing legacy documentation methods (Zettelkasten mind mapping) with modern technology (LLM AI).

- âœ… **LEGACY Expertise**

The true differentiator with AI is not the technical stack. Itâ€™s your actual KnowledgeBase ğŸ§  :  your legacy inputs and your data vaults, maintained and documented over time, which feed the model. This brings back the power to collaboration ğŸ¤ and knowledge sharing â™»ï¸. Offshoring to external brains starts showing its limit, be it through â€˜turnkeyâ€™ workforce or â€˜off-the-shelfâ€™ technology â€¦ In the Human versus Artificial battle, Humans are far from being obsolete !


# For more info : why using RAG ? 

*Source:* [How does RAG work ?](https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-1?hl=en)

<img src="./images/why_using_RAG.png" alt="Image overview" width="500"/> 